# ğŸ›’ ÃœrÃ¼n EÅŸleÅŸtirme Projesi (Advanced Product Matching)

Bu proje, kullanÄ±cÄ± tarafÄ±ndan girilen Ã§eÅŸitli Ã¼rÃ¼n baÅŸlÄ±klarÄ±nÄ± (`Product Title`), standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ gerÃ§ek Ã¼rÃ¼n tanÄ±mlayÄ±cÄ±larÄ± (`Cluster Label`) ile eÅŸleÅŸtirmek ve gruplamak iÃ§in geliÅŸtirilmiÅŸtir. Proje, metin Ã¶n iÅŸleme, derin Ã¶ÄŸrenme tabanlÄ± metin embedding (Sentence-BERT), Ã§eÅŸitli kÃ¼meleme algoritmalarÄ± ve kapsamlÄ± performans deÄŸerlendirme metodolojilerini iÃ§ermektedir.

## ğŸ¯ Projenin AmacÄ±

Temel amaÃ§, e-ticaret platformlarÄ±, fiyat karÅŸÄ±laÅŸtÄ±rma siteleri veya envanter sistemleri gibi kaynaklardan gelen, farklÄ± formatlarda ve detaylarda olabilen Ã¼rÃ¼n baÅŸlÄ±klarÄ±nÄ± analiz ederek:
1.  Bu baÅŸlÄ±klarÄ±n hangi **gerÃ§ek ve standart Ã¼rÃ¼ne** (veri setindeki `Cluster Label` ile temsil edilen) ait olduÄŸunu tespit etmek.
2.  AynÄ± gerÃ§ek Ã¼rÃ¼ne iÅŸaret eden farklÄ± yazÄ±lÄ±mlÄ± baÅŸlÄ±klarÄ± **anlamsal olarak aynÄ± kÃ¼mede** toplamak.
3.  Bu eÅŸleÅŸtirme ve kÃ¼meleme iÅŸleminin performansÄ±nÄ±, Ã¶zellikle **F1 Skoru** baÅŸta olmak Ã¼zere Ã§eÅŸitli metriklerle `Cluster Label` referans alÄ±narak deÄŸerlendirmek.

## âœ¨ Temel Ã–zellikler

*   **Veri YÃ¼kleme ve Analiz:** `sample_data.csv` dosyasÄ±ndan veri yÃ¼kleme, sÃ¼tun temizliÄŸi, temel istatistiklerin Ã§Ä±karÄ±lmasÄ±.
*   **Marka ve Model Ã‡Ä±karÄ±mÄ±:** `Cluster Label`'lardan otomatik marka tespiti (`known_brands.txt`) ve `Product Title`'lardan marka/model tahmini (`extracted_brands_models.txt`).
*   **GeliÅŸmiÅŸ Metin Ã–n Ä°ÅŸleme:** Unicode normalizasyonu, kÃ¼Ã§Ã¼k harfe Ã§evirme, noktalama ve Ã¶zel karakter temizliÄŸi, sayÄ±larÄ±n yazÄ±ya Ã§evrilmesi, marka normalizasyonu, stopword temizliÄŸi ve Ä°ngilizce lemmatizasyon.
*   **Metin Embedding:** `SentenceTransformer` (varsayÄ±lan: `all-MiniLM-L6-v2`) ile Ã¼rÃ¼n baÅŸlÄ±klarÄ±ndan yoÄŸun vektÃ¶r temsilleri (embedding) oluÅŸturma.
*   **KapsamlÄ± KÃ¼meleme AlgoritmalarÄ±:**
    *   DBSCAN
    *   Agglomerative Clustering
    *   KMeans
    *   Spectral Clustering
    *   HDBSCAN
*   **Parametre Optimizasyonu:** `tune_clustering_algorithms` ile DBSCAN, Agglomerative Clustering ve KMeans iÃ§in F1 skorunu maksimize edecek parametre arama ve sonuÃ§larÄ±n `clustering_param_search_results.csv` dosyasÄ±na kaydedilmesi.
*   **Optimize EdilmiÅŸ KÃ¼meleme:** `cluster_products` iÃ§inde, parametre arama sonuÃ§larÄ±na gÃ¶re optimize edilmiÅŸ parametrelerle kÃ¼meleme yapÄ±lmasÄ±.
*   **Performans DeÄŸerlendirme:** `Cluster Label` referans alÄ±narak ARI, NMI, Silhouette Skoru ve ikili eÅŸleÅŸme bazlÄ± (pairwise) Accuracy, Precision, Recall, F1-Skoru, Sensitivity, Specificity metriklerinin hesaplanmasÄ±.
*   **Zengin GÃ¶rselleÅŸtirmeler:** `gorseller` klasÃ¶rÃ¼nde UMAP/t-SNE ile embedding ve kÃ¼me gÃ¶rselleÅŸtirmeleri, performans karÅŸÄ±laÅŸtÄ±rma heatmap ve bar grafikleri, kÃ¼me daÄŸÄ±lÄ±mlarÄ±, confusion matrix'ler.
*   **DetaylÄ± Raporlama:** `product_matching_report.md` adÄ±nda, veri seti bilgileri, kullanÄ±lan yÃ¶ntemler, tÃ¼m algoritmalarÄ±n performans sonuÃ§larÄ± ve en iyi F1 skorunu veren algoritmanÄ±n vurgulandÄ±ÄŸÄ± bir rapor oluÅŸturma.
*   **Post-processing:** KÃ¼Ã§Ã¼k kÃ¼melerin birleÅŸtirilmesi.
*   **Kategori BazlÄ± Threshold Analizi:** `upm_style_category_threshold_analysis` ile farklÄ± benzerlik eÅŸiklerinde kategori bazlÄ± F1 skoru analizi ve grafiklerinin (`upm_style_f1_vs_threshold_*.png`) oluÅŸturulmasÄ±.

## ğŸ› ï¸ Kurulum

### 1. Ã–n Gereksinimler
*   Python 3.8 veya Ã¼zeri.
*   Conda (Ã¶nerilir) veya baÅŸka bir sanal ortam yÃ¶neticisi.

### 2. Ortam Kurulumu (Conda ile)
```bash
# Yeni bir conda ortamÄ± oluÅŸturun (Ã¶rneÄŸin, product_matching adÄ±nda Python 3.9 ile)
conda create -n product_matching python=3.9 -y

# OrtamÄ± aktifleÅŸtirin
conda activate product_matching
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ±n YÃ¼klenmesi
Proje ana dizinindeyken aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
pip install -r requirements.txt
```
Bu komut, `requirements.txt` dosyasÄ±nda listelenen tÃ¼m gerekli Python kÃ¼tÃ¼phanelerini kuracaktÄ±r.

### 4. Veri DosyasÄ±
Projenin Ã§alÄ±ÅŸmasÄ± iÃ§in `sample_data.csv` (veya `ProductMatcher` sÄ±nÄ±fÄ±nÄ± baÅŸlatÄ±rken belirttiÄŸiniz baÅŸka bir veri dosyasÄ±) proje ana dizininde bulunmalÄ±dÄ±r. `sample_data.csv` dosyasÄ±nÄ±n en azÄ±ndan aÅŸaÄŸÄ±daki sÃ¼tunlarÄ± iÃ§ermesi beklenir:
*   `Product Title`: KullanÄ±cÄ± tarafÄ±ndan girilen veya Ã§eÅŸitli kaynaklardan gelen Ã¼rÃ¼n baÅŸlÄ±ÄŸÄ±.
*   `Cluster Label`: Her bir Ã¼rÃ¼n iÃ§in standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ, gerÃ§ek ve "temiz" Ã¼rÃ¼n adÄ±/tanÄ±mlayÄ±cÄ±sÄ±. Bu sÃ¼tun, performans deÄŸerlendirmesi iÃ§in referans (ground truth) olarak kullanÄ±lÄ±r.
*   `Cluster ID`: (Opsiyonel, `Cluster Label` daha Ã¶ncelikli) GerÃ§ek Ã¼rÃ¼n gruarÄ±nÄ± belirten bir kimlik.
*   `Category ID`: (Opsiyonel) ÃœrÃ¼n kategorisi kimliÄŸi.
*   `Category Label`: (Opsiyonel, `upm_style_category_threshold_analysis` iÃ§in kullanÄ±lÄ±r) ÃœrÃ¼n kategorisi etiketi.

## ğŸš€ Projeyi Ã‡alÄ±ÅŸtÄ±rma

Proje ana dizinindeyken (ve sanal ortamÄ±nÄ±z aktifken) aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
python main.py
```
Bu komut, `main.py` iÃ§erisindeki `main()` fonksiyonunu tetikleyecek ve tÃ¼m Ã¼rÃ¼n eÅŸleÅŸtirme pipeline'Ä±nÄ± adÄ±m adÄ±m yÃ¼rÃ¼tecektir. Konsolda her adÄ±m hakkÄ±nda bilgi mesajlarÄ± ve ilerleme Ã§ubuklarÄ± gÃ¶receksiniz.

## ğŸ“ Proje YapÄ±sÄ±

```
veri_odev_yusufi/
â”‚
â”œâ”€â”€ main.py                      # Ana Python betiÄŸi, ProductMatcher sÄ±nÄ±fÄ±nÄ± ve ana iÅŸ akÄ±ÅŸÄ±nÄ± iÃ§erir
â”œâ”€â”€ requirements.txt             # Proje iÃ§in gerekli Python kÃ¼tÃ¼phaneleri
â”œâ”€â”€ README.md                    # Bu bilgilendirme dosyasÄ±
â”œâ”€â”€ sample_data.csv              # Ã–rnek veri seti (Product Title, Cluster Label vb. sÃ¼tunlarÄ± iÃ§ermeli)
â”‚
â”œâ”€â”€ gorseller/                   # Ã‡alÄ±ÅŸtÄ±rma sonrasÄ± oluÅŸturulan tÃ¼m gÃ¶rsel dosyalar bu klasÃ¶re kaydedilir
â”‚   â”œâ”€â”€ embedding_visualization_umap.png
â”‚   â”œâ”€â”€ embedding_visualization_t-sne.png
â”‚   â”œâ”€â”€ performance_heatmap.png
â”‚   â”œâ”€â”€ performance_comparison.png
â”‚   â”œâ”€â”€ cluster_distributions.png
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â””â”€â”€ upm_style_f1_vs_threshold_*.png # Kategori bazlÄ± F1 analiz grafikleri
â”‚
â”œâ”€â”€ known_brands.txt             # Cluster Label'lardan tespit edilen markalarÄ±n listesi
â”œâ”€â”€ extracted_brands_models.txt  # Product Title'lardan Ã§Ä±karÄ±lan marka/model tahminleri ve Ã¶rnekleri
â”œâ”€â”€ product_matching_report.md   # Ã‡alÄ±ÅŸtÄ±rma sonrasÄ± oluÅŸturulan detaylÄ± performans raporu
â””â”€â”€ clustering_param_search_results.csv # KÃ¼meleme algoritmalarÄ± iÃ§in yapÄ±lan parametre arama sonuÃ§larÄ±
```

## âš™ï¸ Metodoloji ve Fonksiyonlar (`ProductMatcher` SÄ±nÄ±fÄ±)

Projenin kalbi `main.py` dosyasÄ±ndaki `ProductMatcher` sÄ±nÄ±fÄ±dÄ±r. Ä°ÅŸte bu sÄ±nÄ±fÄ±n temel fonksiyonlarÄ± ve iÅŸleyiÅŸleri:

1.  **`__init__(self, data_path='sample_data.csv')`**
    *   SÄ±nÄ±fÄ± baÅŸlatÄ±r, veri dosyasÄ±nÄ±n yolunu (`data_path`) alÄ±r.
    *   SonuÃ§larÄ±, embedding'leri ve modeli saklamak iÃ§in dahili deÄŸiÅŸkenleri tanÄ±mlar.
    *   `gorseller` adÄ±nda bir klasÃ¶r yoksa oluÅŸturur.

2.  **`extract_brand_model_from_title(self, title)`**
    *   Verilen bir `Product Title` (Ã¼rÃ¼n baÅŸlÄ±ÄŸÄ±) iÃ§inden, `self.known_brands` listesini kullanarak marka ve ardÄ±ndan gelen ilk birkaÃ§ kelimeyi model olarak Ã§Ä±karmaya Ã§alÄ±ÅŸÄ±r.

3.  **`load_and_analyze_data(self)`**
    *   Belirtilen `data_path`'ten CSV dosyasÄ±nÄ± `pandas` DataFrame olarak yÃ¼kler.
    *   SÃ¼tun adlarÄ±ndaki olasÄ± baÅŸ/son boÅŸluklarÄ±nÄ± temizler.
    *   `Cluster Label` sÃ¼tunundaki ilk kelimeleri alarak `self.known_brands` listesini oluÅŸturur ve bu listeyi `known_brands.txt` dosyasÄ±na yazar.
    *   `Product Title` sÃ¼tunundaki her baÅŸlÄ±k iÃ§in `extract_brand_model_from_title` fonksiyonunu kullanarak marka/model Ã§Ä±karÄ±mÄ± yapar ve sonuÃ§larÄ± `extracted_brands_models.txt` dosyasÄ±na Ã¶rneklerle birlikte yazar.
    *   Veri seti hakkÄ±nda temel istatistikler (toplam kayÄ±t, sÃ¼tunlar, benzersiz `Cluster Label` ve kategori sayÄ±sÄ±) basar.
    *   Eksik veri analizi yapar ve baÅŸlÄ±k uzunluk istatistiklerini gÃ¶sterir.

4.  **`preprocess_titles(self)`**
    *   `Product Title` sÃ¼tunundaki baÅŸlÄ±klarÄ± temizler ve standartlaÅŸtÄ±rÄ±r:
        *   Unicode normalizasyonu (NFKD).
        *   KÃ¼Ã§Ã¼k harfe Ã§evirme.
        *   Noktalama iÅŸaretleri ve Ã¶zel karakterlerin boÅŸlukla deÄŸiÅŸtirilmesi (`re.sub(r'[^\w\s]', ' ', title)`).
        *   Fazla boÅŸluklarÄ±n tek boÅŸluÄŸa indirilmesi ve baÅŸ/son boÅŸluklarÄ±n temizlenmesi.
        *   SayÄ±larÄ±n yazÄ±ya Ã§evrilmesi (Ã¶rn: "2" -> "two") (`inflect` kÃ¼tÃ¼phanesi).
        *   Basit bir marka normalizasyonu (statik `known_brands` listesi ve `self.known_brands` ile geliÅŸtirilebilir).
        *   Ä°ngilizce `stopwords` (nltk) ve birden kÄ±sa kelimelerin kaldÄ±rÄ±lmasÄ±.
        *   Ä°ngilizce lemmatizasyon (`WordNetLemmatizer` nltk).
    *   TemizlenmiÅŸ baÅŸlÄ±klarÄ± `clean_title` adÄ±nda yeni bir sÃ¼tuna kaydeder.
    *   Temizlik sonrasÄ± boÅŸ kalan baÅŸlÄ±klarÄ± veri setinden Ã§Ä±karÄ±r.

5.  **`generate_embeddings(self, model_name='all-MiniLM-L6-v2')`**
    *   Belirtilen `model_name` (varsayÄ±lan: `all-MiniLM-L6-v2`) ile bir `SentenceTransformer` modeli yÃ¼kler.
    *   `clean_title` sÃ¼tunundaki temizlenmiÅŸ baÅŸlÄ±klarÄ± kullanarak her baÅŸlÄ±k iÃ§in bir embedding (yoÄŸun vektÃ¶r temsili) oluÅŸturur.
    *   OluÅŸturulan embedding'leri NumPy array formatÄ±nda `self.embeddings` deÄŸiÅŸkenine kaydeder.

6.  **`extract_word_combinations(self, titles)`, `evaluate_combinations(self, combinations, titles)`, `initial_clustering(self, titles, top_combinations)`, `validate_and_recluster(self, clusters, titles, embeddings)`**
    *   Bu fonksiyonlar, `cluster_products` iÃ§inde kullanÄ±lan, kelime kombinasyonlarÄ±na dayalÄ± deneysel bir kÃ¼meleme yaklaÅŸÄ±mÄ±nÄ±n parÃ§alarÄ±dÄ±r. BaÅŸlÄ±klardan 2'li ve 3'lÃ¼ kelime kombinasyonlarÄ± Ã§Ä±karÄ±r, bunlarÄ± frekans, marka iÃ§erme ve uzunluk gibi kriterlere gÃ¶re skorlar, en iyi kombinasyonlara gÃ¶re ilk kÃ¼meleri oluÅŸturur ve ardÄ±ndan bu kÃ¼meleri embedding benzerliklerine gÃ¶re doÄŸrular ve yeniden dÃ¼zenler. *(Not: `cluster_products` metodunun gÃ¼ncel halinde bu Ã¶zel yaklaÅŸÄ±mÄ±n yanÄ± sÄ±ra standart kÃ¼meleme algoritmalarÄ± da optimize edilmiÅŸ parametrelerle kullanÄ±lmaktadÄ±r.)*

7.  **`cluster_products(self, algorithms=['dbscan', 'agglomerative', 'kmeans', 'spectral', 'hdbscan'])`**
    *   Belirtilen `algorithms` listesindeki her bir kÃ¼meleme algoritmasÄ±nÄ± `self.embeddings` Ã¼zerine uygular.
    *   **Optimize EdilmiÅŸ Parametreler:**
        *   **DBSCAN:** `eps=0.23`, `min_samples=2`, `metric='cosine'` (F1 optimizasyonundan).
        *   **Agglomerative Clustering:** `linkage='ward'`, `metric='euclidean'`, `n_clusters` (varsayÄ±lan olarak `Cluster Label` sayÄ±sÄ±na eÅŸit, F1 optimizasyonundan).
        *   **KMeans:** `n_clusters=200` (F1 optimizasyonundan).
        *   **Spectral Clustering:** `n_clusters` (`Cluster Label` sayÄ±sÄ±na eÅŸit), `affinity='nearest_neighbors'`.
        *   **HDBSCAN:** `min_cluster_size=5`, `metric='euclidean'`.
    *   Her algoritmanÄ±n Ã¼rettiÄŸi kÃ¼me etiketlerini `self.results['clustering']` altÄ±nda saklar.

8.  **`evaluate_performance(self)`**
    *   `self.results['clustering']` altÄ±nda saklanan her kÃ¼meleme algoritmasÄ±nÄ±n sonuÃ§larÄ±nÄ±, `self.df['Cluster Label'].values` (gerÃ§ek Ã¼rÃ¼n etiketleri) ile karÅŸÄ±laÅŸtÄ±rarak performans metrikleri hesaplar:
        *   **KÃ¼meleme Metrikleri:** Adjusted Rand Score (ARI), Normalized Mutual Information (NMI), Silhouette Score.
        *   **Ä°kili EÅŸleÅŸme BazlÄ± Metrikler (Pairwise):** Rastgele seÃ§ilen Ã¼rÃ¼n Ã§iftlerinin aynÄ± `Cluster Label`'a sahip olup olmadÄ±ÄŸÄ± (gerÃ§ek durum) ile aynÄ± kÃ¼meye atanÄ±p atanmadÄ±ÄŸÄ± (tahmini durum) karÅŸÄ±laÅŸtÄ±rÄ±larak Accuracy, Precision, Recall, F1-Score, Sensitivity (Recall ile aynÄ±) ve Specificity hesaplanÄ±r.
    *   Hesaplanan tÃ¼m metrikleri `self.results['evaluation']` altÄ±nda saklar.

9.  **`visualize_results(self)`**
    *   `_plot_embedding_visualization`: UMAP ve t-SNE kullanarak embedding'leri 2D'ye indirger ve hem gerÃ§ek `Cluster ID`'lere (gÃ¶rsel referans iÃ§in) hem de her bir algoritmanÄ±n tahmin ettiÄŸi kÃ¼melere gÃ¶re renklendirilmiÅŸ saÃ§Ä±lÄ±m grafikleri oluÅŸturur (`embedding_visualization_umap.png`, `embedding_visualization_t-sne.png`).
    *   `_plot_performance_comparison`: `self.results['evaluation']`'daki metrikleri kullanarak algoritmalarÄ±n performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran bir heatmap (`performance_heatmap.png`) ve her metrik iÃ§in ayrÄ± bar grafikler (`performance_comparison.png`) oluÅŸturur.
    *   `_plot_cluster_distribution`: GerÃ§ek `Cluster ID` daÄŸÄ±lÄ±mÄ±nÄ± ve seÃ§ilen birkaÃ§ algoritmanÄ±n Ã¼rettiÄŸi kÃ¼me boyutlarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steren bar grafikler oluÅŸturur (`cluster_distributions.png`).
    *   `_plot_confusion_matrices`: Ä°kili eÅŸleÅŸme bazlÄ± deÄŸerlendirme iÃ§in her algoritmanÄ±n bir confusion matrix'ini oluÅŸturur (`confusion_matrices.png`).
    *   TÃ¼m gÃ¶rseller `gorseller/` klasÃ¶rÃ¼ne kaydedilir.

10. **`generate_report(self)`**
    *   Projenin Ã§alÄ±ÅŸmasÄ± hakkÄ±nda detaylÄ± bir Markdown raporu (`product_matching_report.md`) oluÅŸturur. Rapor ÅŸunlarÄ± iÃ§erir:
        *   Veri seti bilgileri.
        *   KullanÄ±lan model ve yÃ¶ntemler.
        *   Her kÃ¼meleme algoritmasÄ± iÃ§in tÃ¼m performans metrikleri.
        *   En iyi F1 skorunu elde eden algoritmanÄ±n vurgulanmasÄ±.
        *   Temel bulgular ve geliÅŸtirme Ã¶nerileri.

11. **`tune_clustering_algorithms(self)`**
    *   DBSCAN, Agglomerative Clustering ve KMeans iÃ§in farklÄ± parametre kombinasyonlarÄ±nÄ± deneyerek bir grid search/parametre arama iÅŸlemi yapar.
    *   Her kombinasyon iÃ§in ARI, NMI ve ikili eÅŸleÅŸme bazlÄ± F1 skorunu (referans olarak `Cluster ID` kullanarak, bu kÄ±sÄ±m `Cluster Label`'a gÃ¼ncellenebilir/paralel Ã§alÄ±ÅŸtÄ±rÄ±labilir) hesaplar.
    *   SonuÃ§larÄ± konsola basar ve `clustering_param_search_results.csv` dosyasÄ±na kaydeder. Bu dosya, `cluster_products` fonksiyonundaki algoritmalarÄ±n parametrelerini optimize etmek iÃ§in kullanÄ±lÄ±r.

12. **`postprocess_clusters(self, min_cluster_size=5)`**
    *   Her kÃ¼meleme algoritmasÄ±nÄ±n Ã¼rettiÄŸi kÃ¼melerden, belirtilen `min_cluster_size`'dan daha az elemana sahip olan kÃ¼Ã§Ã¼k kÃ¼meleri bulur.
    *   Bu kÃ¼Ã§Ã¼k kÃ¼melerdeki elemanlarÄ±, embedding uzayÄ±nda kendilerine en yakÄ±n (gÃ¼rÃ¼ltÃ¼ olmayan) komÅŸularÄ±nÄ±n bulunduÄŸu kÃ¼meye atayarak birleÅŸtirir.

13. **`upm_style_category_threshold_analysis(self, thresholds=np.arange(0.1, 1.0, 0.1), algorithms=['kmeans', 'agglomerative', 'dbscan'])`**
    *   Her bir Ã¼rÃ¼n kategorisi (`Category Label`) ve tÃ¼m veri seti iÃ§in, belirtilen kÃ¼meleme algoritmalarÄ±nÄ± farklÄ± benzerlik eÅŸik deÄŸerleri (DBSCAN iÃ§in `eps` olarak kullanÄ±lÄ±r, diÄŸerleri iÃ§in dolaylÄ± etki) ile Ã§alÄ±ÅŸtÄ±rÄ±r.
    *   Her kategori, algoritma ve eÅŸik deÄŸeri iÃ§in ikili eÅŸleÅŸme bazlÄ± F1 skorunu (referans olarak `Cluster ID` kullanarak, bu kÄ±sÄ±m da `Cluster Label`'a gÃ¼ncellenebilir/paralel Ã§alÄ±ÅŸtÄ±rÄ±labilir) hesaplar.
    *   SonuÃ§larÄ±, her kategori iÃ§in F1 skorunun eÅŸik deÄŸerine karÅŸÄ± deÄŸiÅŸimini gÃ¶steren Ã§izgi grafikleri olarak (`gorseller/upm_style_f1_vs_threshold_*.png`) kaydeder.

## ğŸ’¡ F1 Skoru ve Optimizasyon

Bu projede **F1 Skoru**, kullanÄ±cÄ± tarafÄ±ndan girilen `Product Title`'larÄ±n, gerÃ§ek Ã¼rÃ¼n kimlikleri olan `Cluster Label`'lar ile ne kadar baÅŸarÄ±lÄ± bir ÅŸekilde eÅŸleÅŸtirildiÄŸinin ana gÃ¶stergelerinden biridir. YÃ¼ksek F1 skoru, modelin hem doÄŸru Ã¼rÃ¼nleri bir araya getirmede (Recall) hem de bunu yaparken farklÄ± Ã¼rÃ¼nleri karÄ±ÅŸtÄ±rmamada (Precision) baÅŸarÄ±lÄ± olduÄŸu anlamÄ±na gelir. `evaluate_performance` fonksiyonu, bu F1 skorunu `Cluster Label`'larÄ± referans alarak hesaplar. `cluster_products` fonksiyonundaki algoritmalarÄ±n (Ã¶zellikle DBSCAN, Agglomerative, KMeans) parametreleri, `tune_clustering_algorithms` adÄ±mÄ±ndan elde edilen ve F1 skorunu maksimize etmeyi hedefleyen deÄŸerlerle gÃ¼ncellenmiÅŸtir.

## ğŸ”§ OlasÄ± GeliÅŸtirmeler ve Ä°puÃ§larÄ±
*   `preprocess_titles` iÃ§indeki `normalize_brand` fonksiyonunu, `load_and_analyze_data` iÃ§inde `Cluster Label`'lardan dinamik olarak oluÅŸturulan `self.known_brands` listesini kullanacak ÅŸekilde gÃ¼ncelleyebilirsiniz.
*   `tune_clustering_algorithms` ve `upm_style_category_threshold_analysis` fonksiyonlarÄ±ndaki referans etiketlerin (ÅŸu anda bazÄ± yerlerde `Cluster ID` olabilir) tutarlÄ± bir ÅŸekilde `Cluster Label` olmasÄ±nÄ± saÄŸlayabilirsiniz.
*   FarklÄ± SentenceTransformer modelleri (`all-mpnet-base-v2` gibi daha bÃ¼yÃ¼k modeller veya e-ticarete Ã¶zel modeller) deneyerek embedding kalitesini artÄ±rabilirsiniz.
*   Metin Ã¶n iÅŸleme adÄ±mlarÄ±nÄ± (`stopwords` listesi, normalizasyon kurallarÄ±) veri setinize ve `Cluster Label`'larÄ±nÄ±zÄ±n yapÄ±sÄ±na gÃ¶re daha da Ã¶zelleÅŸtirebilirsiniz.

## ğŸ› Sorun Giderme
*   **Python SÃ¼rÃ¼mÃ¼ ve Ortam SorunlarÄ±:** Projenin Python 3.8+ ve `requirements.txt` ile kurulan bir sanal ortamda Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±ndan emin olun.
*   **KÃ¼tÃ¼phane Ä°ndirme HatalarÄ± (nltk):** `nltk.download('stopwords')` ve `nltk.download('wordnet')` komutlarÄ± ilk Ã§alÄ±ÅŸtÄ±rmada internet baÄŸlantÄ±sÄ± gerektirir. BaÅŸarÄ±sÄ±z olursa manuel olarak Python interpretÃ¶rÃ¼nde Ã§alÄ±ÅŸtÄ±rÄ±labilir.
*   **Bellek HatalarÄ± (Memory Error):** Ã‡ok bÃ¼yÃ¼k veri setleriyle Ã§alÄ±ÅŸÄ±rken, `evaluate_performance` ve `visualize_results` gibi fonksiyonlardaki `sample_size` deÄŸerlerini kÃ¼Ã§Ã¼ltmeyi veya daha fazla RAM'e sahip bir ortamda Ã§alÄ±ÅŸmayÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

---
Bu `README.md` dosyasÄ±, projenin mevcut durumu ve yetenekleri hakkÄ±nda kapsamlÄ± bir genel bakÄ±ÅŸ sunar.
